{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pobranie i rozpakowanie datasetu aut z polskimi tablicami rejestracyjnymi"
      ],
      "metadata": {
        "id": "I2Q6TFEHFwQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d piotrstefaskiue/poland-vehicle-license-plate-dataset\n",
        "!unzip poland-vehicle-license-plate-dataset -d /content\n",
        "!rm poland-vehicle-license-plate-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsGG7nseCmB3",
        "outputId": "27597204-007e-42f7-9fed-fbef5df6a541",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/piotrstefaskiue/poland-vehicle-license-plate-dataset\n",
            "License(s): other\n",
            "Downloading poland-vehicle-license-plate-dataset.zip to /content\n",
            "100% 472M/474M [00:07<00:00, 76.9MB/s]\n",
            "100% 474M/474M [00:07<00:00, 66.7MB/s]\n",
            "Archive:  poland-vehicle-license-plate-dataset.zip\n",
            "  inflating: /content/annotations.xml  \n",
            "  inflating: /content/photos/1.jpg   \n",
            "  inflating: /content/photos/10.jpg  \n",
            "  inflating: /content/photos/100.jpg  \n",
            "  inflating: /content/photos/101.jpg  \n",
            "  inflating: /content/photos/102.jpg  \n",
            "  inflating: /content/photos/103.jpg  \n",
            "  inflating: /content/photos/104.jpg  \n",
            "  inflating: /content/photos/105.jpg  \n",
            "  inflating: /content/photos/106.jpg  \n",
            "  inflating: /content/photos/107.jpg  \n",
            "  inflating: /content/photos/108.jpg  \n",
            "  inflating: /content/photos/109.jpg  \n",
            "  inflating: /content/photos/11.jpg  \n",
            "  inflating: /content/photos/110.jpg  \n",
            "  inflating: /content/photos/111.jpg  \n",
            "  inflating: /content/photos/112.jpg  \n",
            "  inflating: /content/photos/113.jpg  \n",
            "  inflating: /content/photos/114.jpg  \n",
            "  inflating: /content/photos/115.jpg  \n",
            "  inflating: /content/photos/116.jpg  \n",
            "  inflating: /content/photos/117.jpg  \n",
            "  inflating: /content/photos/118.jpg  \n",
            "  inflating: /content/photos/119.jpg  \n",
            "  inflating: /content/photos/12.jpg  \n",
            "  inflating: /content/photos/120.jpg  \n",
            "  inflating: /content/photos/121.jpg  \n",
            "  inflating: /content/photos/122.jpg  \n",
            "  inflating: /content/photos/123.jpg  \n",
            "  inflating: /content/photos/124.jpg  \n",
            "  inflating: /content/photos/125.jpg  \n",
            "  inflating: /content/photos/126.jpg  \n",
            "  inflating: /content/photos/127.jpg  \n",
            "  inflating: /content/photos/128.jpg  \n",
            "  inflating: /content/photos/129.jpg  \n",
            "  inflating: /content/photos/13.jpg  \n",
            "  inflating: /content/photos/130.jpg  \n",
            "  inflating: /content/photos/131.jpg  \n",
            "  inflating: /content/photos/132.jpg  \n",
            "  inflating: /content/photos/133.jpg  \n",
            "  inflating: /content/photos/134.jpg  \n",
            "  inflating: /content/photos/135.jpg  \n",
            "  inflating: /content/photos/136.jpg  \n",
            "  inflating: /content/photos/137.jpg  \n",
            "  inflating: /content/photos/138.jpg  \n",
            "  inflating: /content/photos/139.jpg  \n",
            "  inflating: /content/photos/14.jpg  \n",
            "  inflating: /content/photos/140.jpg  \n",
            "  inflating: /content/photos/141.jpg  \n",
            "  inflating: /content/photos/142.jpg  \n",
            "  inflating: /content/photos/143(1).jpg  \n",
            "  inflating: /content/photos/143.jpg  \n",
            "  inflating: /content/photos/144.jpg  \n",
            "  inflating: /content/photos/145.jpg  \n",
            "  inflating: /content/photos/146.jpg  \n",
            "  inflating: /content/photos/147.jpg  \n",
            "  inflating: /content/photos/148.jpg  \n",
            "  inflating: /content/photos/149.jpg  \n",
            "  inflating: /content/photos/15.jpg  \n",
            "  inflating: /content/photos/150.jpg  \n",
            "  inflating: /content/photos/151.jpg  \n",
            "  inflating: /content/photos/152.jpg  \n",
            "  inflating: /content/photos/153.jpg  \n",
            "  inflating: /content/photos/154.jpg  \n",
            "  inflating: /content/photos/155.jpg  \n",
            "  inflating: /content/photos/156.jpg  \n",
            "  inflating: /content/photos/157.jpg  \n",
            "  inflating: /content/photos/158.jpg  \n",
            "  inflating: /content/photos/159.jpg  \n",
            "  inflating: /content/photos/16.jpg  \n",
            "  inflating: /content/photos/160.jpg  \n",
            "  inflating: /content/photos/161.jpg  \n",
            "  inflating: /content/photos/162.jpg  \n",
            "  inflating: /content/photos/163.jpg  \n",
            "  inflating: /content/photos/164.jpg  \n",
            "  inflating: /content/photos/165.jpg  \n",
            "  inflating: /content/photos/166.jpg  \n",
            "  inflating: /content/photos/167.jpg  \n",
            "  inflating: /content/photos/168.jpg  \n",
            "  inflating: /content/photos/169.jpg  \n",
            "  inflating: /content/photos/17.jpg  \n",
            "  inflating: /content/photos/170.jpg  \n",
            "  inflating: /content/photos/171.jpg  \n",
            "  inflating: /content/photos/172.jpg  \n",
            "  inflating: /content/photos/173.jpg  \n",
            "  inflating: /content/photos/174.jpg  \n",
            "  inflating: /content/photos/175.jpg  \n",
            "  inflating: /content/photos/176.jpg  \n",
            "  inflating: /content/photos/177.jpg  \n",
            "  inflating: /content/photos/178.jpg  \n",
            "  inflating: /content/photos/179.jpg  \n",
            "  inflating: /content/photos/18.jpg  \n",
            "  inflating: /content/photos/180.jpg  \n",
            "  inflating: /content/photos/181.jpg  \n",
            "  inflating: /content/photos/182.jpg  \n",
            "  inflating: /content/photos/183.jpg  \n",
            "  inflating: /content/photos/184.jpg  \n",
            "  inflating: /content/photos/185.jpg  \n",
            "  inflating: /content/photos/186.jpg  \n",
            "  inflating: /content/photos/187.jpg  \n",
            "  inflating: /content/photos/188.jpg  \n",
            "  inflating: /content/photos/189.jpg  \n",
            "  inflating: /content/photos/19.jpg  \n",
            "  inflating: /content/photos/190.jpg  \n",
            "  inflating: /content/photos/191.jpg  \n",
            "  inflating: /content/photos/192.jpg  \n",
            "  inflating: /content/photos/193.jpg  \n",
            "  inflating: /content/photos/194.jpg  \n",
            "  inflating: /content/photos/2.jpg   \n",
            "  inflating: /content/photos/20.jpg  \n",
            "  inflating: /content/photos/21.jpg  \n",
            "  inflating: /content/photos/22.jpg  \n",
            "  inflating: /content/photos/23.jpg  \n",
            "  inflating: /content/photos/24.jpg  \n",
            "  inflating: /content/photos/25.jpg  \n",
            "  inflating: /content/photos/26.jpg  \n",
            "  inflating: /content/photos/27.jpg  \n",
            "  inflating: /content/photos/28.jpg  \n",
            "  inflating: /content/photos/29.jpg  \n",
            "  inflating: /content/photos/3.jpg   \n",
            "  inflating: /content/photos/30.jpg  \n",
            "  inflating: /content/photos/31.jpg  \n",
            "  inflating: /content/photos/32.jpg  \n",
            "  inflating: /content/photos/33.jpg  \n",
            "  inflating: /content/photos/34.jpg  \n",
            "  inflating: /content/photos/35.jpg  \n",
            "  inflating: /content/photos/36.jpg  \n",
            "  inflating: /content/photos/37.jpg  \n",
            "  inflating: /content/photos/38.jpg  \n",
            "  inflating: /content/photos/39.jpg  \n",
            "  inflating: /content/photos/4.jpg   \n",
            "  inflating: /content/photos/40.jpg  \n",
            "  inflating: /content/photos/41.jpg  \n",
            "  inflating: /content/photos/42.jpg  \n",
            "  inflating: /content/photos/43.jpg  \n",
            "  inflating: /content/photos/44.jpg  \n",
            "  inflating: /content/photos/45.jpg  \n",
            "  inflating: /content/photos/46.jpg  \n",
            "  inflating: /content/photos/47.jpg  \n",
            "  inflating: /content/photos/48.jpg  \n",
            "  inflating: /content/photos/49.jpg  \n",
            "  inflating: /content/photos/5.jpg   \n",
            "  inflating: /content/photos/50.jpg  \n",
            "  inflating: /content/photos/51.jpg  \n",
            "  inflating: /content/photos/52.jpg  \n",
            "  inflating: /content/photos/53.jpg  \n",
            "  inflating: /content/photos/54.jpg  \n",
            "  inflating: /content/photos/55.jpg  \n",
            "  inflating: /content/photos/56.jpg  \n",
            "  inflating: /content/photos/57.jpg  \n",
            "  inflating: /content/photos/58.jpg  \n",
            "  inflating: /content/photos/59.jpg  \n",
            "  inflating: /content/photos/6.jpg   \n",
            "  inflating: /content/photos/60.jpg  \n",
            "  inflating: /content/photos/61.jpg  \n",
            "  inflating: /content/photos/62.jpg  \n",
            "  inflating: /content/photos/63.jpg  \n",
            "  inflating: /content/photos/64.jpg  \n",
            "  inflating: /content/photos/65.jpg  \n",
            "  inflating: /content/photos/66.jpg  \n",
            "  inflating: /content/photos/67.jpg  \n",
            "  inflating: /content/photos/68.jpg  \n",
            "  inflating: /content/photos/69.jpg  \n",
            "  inflating: /content/photos/7.jpg   \n",
            "  inflating: /content/photos/70.jpg  \n",
            "  inflating: /content/photos/71.jpg  \n",
            "  inflating: /content/photos/72.jpg  \n",
            "  inflating: /content/photos/73.jpg  \n",
            "  inflating: /content/photos/74.jpg  \n",
            "  inflating: /content/photos/75.jpg  \n",
            "  inflating: /content/photos/76.jpg  \n",
            "  inflating: /content/photos/77.jpg  \n",
            "  inflating: /content/photos/78.jpg  \n",
            "  inflating: /content/photos/79.jpg  \n",
            "  inflating: /content/photos/8.jpg   \n",
            "  inflating: /content/photos/80.jpg  \n",
            "  inflating: /content/photos/81.jpg  \n",
            "  inflating: /content/photos/82.jpg  \n",
            "  inflating: /content/photos/83.jpg  \n",
            "  inflating: /content/photos/84.jpg  \n",
            "  inflating: /content/photos/85.jpg  \n",
            "  inflating: /content/photos/86.jpg  \n",
            "  inflating: /content/photos/87.jpg  \n",
            "  inflating: /content/photos/88.jpg  \n",
            "  inflating: /content/photos/89.jpg  \n",
            "  inflating: /content/photos/9.jpg   \n",
            "  inflating: /content/photos/90.jpg  \n",
            "  inflating: /content/photos/91.jpg  \n",
            "  inflating: /content/photos/92.jpg  \n",
            "  inflating: /content/photos/93.jpg  \n",
            "  inflating: /content/photos/94.jpg  \n",
            "  inflating: /content/photos/95.jpg  \n",
            "  inflating: /content/photos/96.jpg  \n",
            "  inflating: /content/photos/97.jpg  \n",
            "  inflating: /content/photos/98.jpg  \n",
            "  inflating: /content/photos/99.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wyciągnięcie pojedynczych znaków ze zbioru tablic rejestracyjnych\n",
        "\n"
      ],
      "metadata": {
        "id": "J0OVIWHfGE0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "from skimage.filters import threshold_local\n",
        "\n",
        "# przetworzenie tablicy rejestracyjnej\n",
        "def process_image(image_path = None, img = None, debug_folder=None, blur_ksize=(5, 5)):\n",
        "    # folder na podgląd poszczególnych etapów przetwarzania\n",
        "    if debug_folder is not None:\n",
        "        os.makedirs(debug_folder, exist_ok=True)\n",
        "\n",
        "    # wczytywanie obrazka tablicy rejestracyjnej ze ścieżki\n",
        "    if image_path is not None:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Błąd: Nie można wczytać obrazu\")\n",
        "    # używanie przekazanego obrazka tablicy rejestracyjnej\n",
        "    elif img is not None:\n",
        "        image = img\n",
        "    else:\n",
        "        raise ValueError(\"Nie przekazano obrazu lub sciezki\")\n",
        "\n",
        "    save_count = 0\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_org.png\"), image)\n",
        "        save_count += 1\n",
        "\n",
        "    # rozmyty obrazek, polepsza efekty binaryzacji\n",
        "    image = cv2.GaussianBlur(image, blur_ksize, 0)\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_blurred.png\"), image)\n",
        "        save_count += 1\n",
        "    # kanał niebieski i czerwony, używane do usunięcia eurobandu\n",
        "    # alternatywnie możnaby skorzystać w tym celu ze składowej H modelu HSV\n",
        "    # (ale nie zostało to przetestowane)\n",
        "    B = image[:,:,0]\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_blue.png\"), B)\n",
        "        save_count += 1\n",
        "    R = image[:,:,2]\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_red.png\"), R)\n",
        "        save_count += 1\n",
        "    Bh, Bw = B.shape[:]\n",
        "    # wartość bezwględna różnicy między kanałem niebieskim a czerwonym, przy\n",
        "    # jednorodnie oświetlonych obrazach pozwala na skuteczną lokalizację eurobandu\n",
        "    abs_diff = np.zeros(B.shape[:], dtype=np.uint8)\n",
        "    for h in range(Bh):\n",
        "        for w in range(Bw):\n",
        "            abs_diff[h][w] = abs(int(B[h][w])-int(R[h][w]))\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_BR_diff.png\"), abs_diff)\n",
        "        save_count += 1\n",
        "    # maska pozwalająca usunąć euroband\n",
        "    _, diff_thresh = cv2.threshold(abs_diff, 40, 255, cv2.THRESH_BINARY)\n",
        "    diff_thresh = cv2.bitwise_not(diff_thresh)\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_BR_diff_thresh.png\"), diff_thresh)\n",
        "        save_count += 1\n",
        "\n",
        "    # kanał value z modelu HSV pozwala na precyzyjne oddzielenie znaków z tablicy\n",
        "    # rejestracyjnej\n",
        "    V = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))[2]\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_value.png\"), V)\n",
        "        save_count += 1\n",
        "    # progowanie adaptacyjne kanału value\n",
        "    T = threshold_local(V, 61, offset=15, method=\"gaussian\")\n",
        "    image = (V > T).astype(\"uint8\") * 255\n",
        "    # negacja obrazu, aby obiekty były białem\n",
        "    image = cv2.bitwise_not(image)\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_thresh.png\"), image)\n",
        "        save_count += 1\n",
        "    # iloczyn z maską usuwającą euroband\n",
        "    image = cv2.bitwise_and(image, diff_thresh)\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_thresh_bitand.png\"), image)\n",
        "        save_count += 1\n",
        "    return image\n",
        "\n",
        "# sprawdza czy dany kontur dotyka krawędzi obrazka\n",
        "def touches_border(contour, lh, lw):\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "    if x <= 1 or y <= 1 or abs(lw - (x + w)) <= 1 or abs(lh - (y + h)) <= 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# funkcja wydzielająca segmenty, w których znajdują się litery\n",
        "def get_characters_images(license_plate_image, debug_folder = None, min_char_height_factor=0.4,\n",
        "                    max_char_height_factor=0.9, min_char_aspect_ratio=1., max_char_aspect_ratio=10.,\n",
        "                    min_char_width_factor = 0.015, max_char_width_factor = 0.18):\n",
        "    # folder na podgląd poszczególnych etapów przetwarzania\n",
        "    if debug_folder is not None:\n",
        "        os.makedirs(debug_folder, exist_ok = True)\n",
        "\n",
        "    image = license_plate_image\n",
        "    save_count = 0\n",
        "\n",
        "    # znalezienie konturów obiektów z przekazanego obrazka\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # określenie warunków określających czy dany obiekt jest znakiem\n",
        "    lh, lw = license_plate_image.shape[:2]\n",
        "    min_char_height = min_char_height_factor * lh\n",
        "    max_char_height = max_char_height_factor * lh\n",
        "    min_char_width = min_char_width_factor * lw\n",
        "    max_char_width = max_char_width_factor * lw\n",
        "    # maska na znaki, pozwalająca oczyścić obrazek z niepotrzebnych konturów\n",
        "    chars_mask = np.zeros(image.shape[:], dtype=np.uint8)\n",
        "\n",
        "    for i, contour in enumerate(contours):\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        aspect_ratio = h / w\n",
        "        # jesli dany kontur spełnia warunki, to rysujemy jego wypełnienie na masce\n",
        "        if (min_char_height <= h <= max_char_height and min_char_aspect_ratio <= aspect_ratio <= max_char_aspect_ratio\n",
        "                and min_char_width <= w <= max_char_width and (touches_border(contour, lh, lw) == False)):\n",
        "            cv2.drawContours(chars_mask, [contour], 0, (255,), -1)\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_chars_mask.png\"), chars_mask)\n",
        "        save_count += 1\n",
        "    # iloczyn przetworzonej tablicy rejestracyjnej z maską znaków\n",
        "    chars_image = cv2.bitwise_and(image, chars_mask)\n",
        "    if debug_folder is not None:\n",
        "        cv2.imwrite(os.path.join(debug_folder, f\"{save_count}_chars_image.png\"), chars_image)\n",
        "        save_count += 1\n",
        "\n",
        "    # [wycięty znak]\n",
        "    characters = []\n",
        "    # [składowa x lewej krawędzi bounding boxa konturu,\n",
        "    # składowa x prawej krawędzi bounding boxa konturu]\n",
        "    # służy do znalezienia największej przerwy między znakami, czyli do przerwy\n",
        "    # między wyróżnikiem miejsca a wyróżnikiem pojazdu\n",
        "    char_locations = []\n",
        "    # kontury znaków, posortowane po składowej x, dzięki czemy możemy zapisać je\n",
        "    # w odpowiedniej kolejności\n",
        "    contours, _ = cv2.findContours(chars_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
        "    for i, contour in enumerate(contours):\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        char = chars_image[y:y + h, x:x + w]\n",
        "        characters.append(char)\n",
        "        char_locations.append((x, x+w))\n",
        "        if debug_folder is not None:\n",
        "            char_path = os.path.join(debug_folder, f\"char_{x}.png\")\n",
        "            cv2.imwrite(char_path, char)\n",
        "\n",
        "    # znalezienie indeksu największej przerwy między znakami\n",
        "    max_gap = 0\n",
        "    max_gap_index = -1\n",
        "    for i in range(1, len(char_locations)):\n",
        "        gap = char_locations[i][0] - char_locations[i-1][1]\n",
        "        if gap > max_gap:\n",
        "            max_gap = gap\n",
        "            max_gap_index = i\n",
        "    return characters, max_gap_index"
      ],
      "metadata": {
        "id": "OpY8tppJ7p5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvWq0WaaBaGh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# utworzenie słownika znaków występujących na polskich rejestracjach\n",
        "valid_characters = '0123456789ABCDEFGHIJKLMNOPRSTUVWXYZ'\n",
        "CHARS = {char: index for index, char in enumerate(valid_characters)}\n",
        "\n",
        "def extract_characters_from_data(debug = False):\n",
        "    xml_file = \"annotations.xml\"  # Plik XML z danymi o tablicach\n",
        "    images_folder = \"photos\"  # Folder z obrazami\n",
        "    target_folder = \"characters\"  # Folder na wycięte znaki z tablic rejestracyjnych\n",
        "    output_txt_file = \"labels.txt\"  # Plik tekstowy na etykiety znaków\n",
        "\n",
        "    os.makedirs(target_folder, exist_ok=True)\n",
        "    # statystyki na temat tego ile tablic rejestracyjnych udało się odczytać z dobrą\n",
        "    # ilościa znaków\n",
        "    total_plates = 0\n",
        "    well_read_plates = 0\n",
        "    # statystyki na temat tego ile jakich znaków na ile możliwych udało się\n",
        "    # uzyskać ze zbioru danych\n",
        "    chars_count = [0 for _ in CHARS]\n",
        "    total_chars_count = [0 for _ in CHARS]\n",
        "\n",
        "    # Otwórz plik tekstowy do zapisu danych o tablicach\n",
        "    with open(output_txt_file, \"w\", encoding=\"utf-8\") as output_file:\n",
        "        # Wczytaj i sparsuj plik XML\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Iteracja po elementach <image> w pliku XML\n",
        "        for image in root.findall(\".//image\"):\n",
        "            image_name = image.get(\"name\")\n",
        "            image_path = os.path.join(images_folder, image_name)\n",
        "\n",
        "            if not os.path.exists(image_path):\n",
        "                continue\n",
        "\n",
        "            img = cv2.imread(image_path)\n",
        "            for box in image.findall(\".//box[@label='plate']\"):\n",
        "                # Pobierz współrzędne tablicy rejestracyjnej\n",
        "                xtl = int(float(box.get(\"xtl\")))\n",
        "                ytl = int(float(box.get(\"ytl\")))\n",
        "                xbr = int(float(box.get(\"xbr\")))\n",
        "                ybr = int(float(box.get(\"ybr\")))\n",
        "\n",
        "                # Wytnij tablicę rejestracyjną z obrazu\n",
        "                cropped = img[ytl:ybr, xtl:xbr]\n",
        "\n",
        "                # Pobierz numer rejestracyjny\n",
        "                plate_number = box.find(\".//attribute[@name='plate number']\").text.replace(\" \", \"\")\n",
        "                # poprawienie błędnej etykiety\n",
        "                if image_name == \"58.jpg\":\n",
        "                    plate_number = \"STA8582C\"\n",
        "                total_plates += 1\n",
        "                for char in plate_number:\n",
        "                    total_chars_count[CHARS[char]] += 1\n",
        "                # nazwa pliku bez rozszerzenia\n",
        "                simple_image_name = image_name[:-4]\n",
        "                try:\n",
        "                    if debug == True:\n",
        "                        processed_license_plate = process_image(img = cropped,\n",
        "                                    debug_folder = f\"debug/{simple_image_name}\")\n",
        "                    else:\n",
        "                        processed_license_plate = process_image(img = cropped)\n",
        "                except ValueError as e:\n",
        "                    print(f\"{e}, {image_name}\")\n",
        "                    continue\n",
        "                if debug == True:\n",
        "                    characters, space_location = get_characters_images(processed_license_plate,\n",
        "                                            debug_folder = f\"debug/{simple_image_name}/chars\")\n",
        "                else:\n",
        "                    characters, space_location = get_characters_images(processed_license_plate)\n",
        "\n",
        "                if len(characters) != len(plate_number):\n",
        "                    if debug == True:\n",
        "                        print(f\"Extracted {len(characters)} characters in {image_name}, should be {len(plate_number)}, skipping\")\n",
        "                    continue\n",
        "                well_read_plates += 1\n",
        "\n",
        "                # Zapisz wycięte znaki\n",
        "                for i, character in enumerate(characters):\n",
        "                    character_path = os.path.join(target_folder, f\"{simple_image_name}_{i}.png\")\n",
        "                    cv2.imwrite(character_path, reshape_character(character))\n",
        "                    #cv2.imwrite(character_path, character)\n",
        "                    output_file.write(f\"{simple_image_name}_{i}.png, {CHARS[plate_number[i]]}\\n\")\n",
        "                    chars_count[CHARS[plate_number[i]]] += 1\n",
        "    if debug == True:\n",
        "        print(f\"Udało się odczytać prawidłową liczbę znaków z {well_read_plates/total_plates*100:.0f}% rejestracji\")\n",
        "        for char, count, total_count in zip(CHARS, chars_count, total_chars_count):\n",
        "            print(f\"{char}: {count}/{total_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# funkcja zmieniająca wymiary obrazka bez deformacji, domyślne rozmiary odpowiadają\n",
        "# wymiarą oczekiwanym przez model klasyfikujący znak\n",
        "def reshape_character(char, target_resized = 216, target_padded = 256):\n",
        "    height, width = char.shape[:2]\n",
        "    bigger_dimension = max(height, width)\n",
        "    resize_ratio = target_resized / bigger_dimension\n",
        "    if resize_ratio > 1:\n",
        "        interpolation = cv2.INTER_CUBIC\n",
        "    else:\n",
        "        interpolation = cv2.INTER_AREA\n",
        "    resized = cv2.resize(char, (0,0), fx=resize_ratio, fy=resize_ratio, interpolation=interpolation)\n",
        "    height, width = resized.shape[:2]\n",
        "    top = (target_padded-height) // 2\n",
        "    bottom = target_padded-height-top\n",
        "    left = (target_padded-width) // 2\n",
        "    right = target_padded-width-left\n",
        "    return cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value = 0)"
      ],
      "metadata": {
        "id": "sR40VZwaSQYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_characters_from_data(debug=True)"
      ],
      "metadata": {
        "id": "dE8tTxATFAss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c344fb5b-0b00-429c-e050-66728ee0cfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 6 characters in 10.jpg, should be 7, skipping\n",
            "Extracted 8 characters in 110.jpg, should be 7, skipping\n",
            "Extracted 6 characters in 112.jpg, should be 7, skipping\n",
            "Extracted 0 characters in 115.jpg, should be 7, skipping\n",
            "Extracted 8 characters in 118.jpg, should be 7, skipping\n",
            "Extracted 5 characters in 143(1).jpg, should be 7, skipping\n",
            "Extracted 5 characters in 143.jpg, should be 7, skipping\n",
            "Extracted 5 characters in 148.jpg, should be 7, skipping\n",
            "Extracted 6 characters in 186.jpg, should be 7, skipping\n",
            "Extracted 6 characters in 24.jpg, should be 7, skipping\n",
            "Extracted 2 characters in 35.jpg, should be 4, skipping\n",
            "Extracted 8 characters in 52.jpg, should be 7, skipping\n",
            "Extracted 1 characters in 6.jpg, should be 7, skipping\n",
            "Extracted 5 characters in 8.jpg, should be 7, skipping\n",
            "Extracted 6 characters in 81.jpg, should be 7, skipping\n",
            "Extracted 9 characters in 84.jpg, should be 8, skipping\n",
            "Udało się odczytać prawidłową liczbę znaków z 92% rejestracji\n",
            "0: 65/70\n",
            "1: 78/83\n",
            "2: 77/79\n",
            "3: 54/60\n",
            "4: 64/69\n",
            "5: 61/67\n",
            "6: 62/73\n",
            "7: 78/82\n",
            "8: 72/78\n",
            "9: 75/81\n",
            "A: 29/32\n",
            "B: 19/19\n",
            "C: 28/30\n",
            "D: 2/3\n",
            "E: 20/21\n",
            "F: 16/17\n",
            "G: 18/20\n",
            "H: 11/14\n",
            "I: 15/15\n",
            "J: 23/24\n",
            "K: 47/52\n",
            "L: 33/39\n",
            "M: 22/22\n",
            "N: 9/9\n",
            "O: 15/18\n",
            "P: 12/12\n",
            "R: 13/16\n",
            "S: 175/188\n",
            "T: 35/38\n",
            "U: 9/12\n",
            "V: 14/15\n",
            "W: 16/16\n",
            "X: 8/10\n",
            "Y: 7/8\n",
            "Z: 16/16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nauka modelu klasyfikującego pojedyncze znaki z tablicy rejestracyjnej"
      ],
      "metadata": {
        "id": "bEM7DaOYiRaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOfCU1SMsgPE",
        "outputId": "b4a96353-b529-4b26-a3d3-39ae5a0af038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
            "Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms.v2 as v2\n",
        "import os, sys, time\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None, target_transform=None):\n",
        "    \t#super().__init__()\n",
        "        self.img_labels = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "\t# ilość danych\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "\t# zwrócenie obrazka i jego etykiety\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path, ImageReadMode.GRAY)\n",
        "\t\t# model oczekuje obrazów RGB, więc kopiujemy jedyną warstwe, aby spełnić\n",
        "\t\t# ten warunek\n",
        "        image = image.repeat(3, 1, 1).float()\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "# uczenie i testowanie modelu\n",
        "def trainAndTest(model, optimizer, train_data_loader, test_data_loader, loss_fn,\n",
        "                 device, preprocess):\n",
        "\t# ustawienie modelu w tryb treningu\n",
        "\tmodel.train()\n",
        "\tfor images, labels in train_data_loader:\n",
        "\t\t# przetworzenie obrazków w sposób oczekiwany przez model\n",
        "\t\timages = preprocess(images)\n",
        "\t\timages = images.to(device)\n",
        "\t\tlabels = labels.to(device)\n",
        "\n",
        "\t\t# uzyskanie predykcji modelu i obliczenie wartości funkcji straty w celu\n",
        "\t\t# nauki modelu\n",
        "\t\toutput = model(images)\n",
        "\t\tloss = loss_fn(output, labels)\n",
        "\n",
        "\t\t# wyzerowanie gradientów z poprzednich iteracji, aby nie aktualizować nimi\n",
        "\t\t# ponownie wag modelu\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t# propagacja wstecz, czyli aktualizacja wag modelu\n",
        "\t\tloss.backward()\n",
        "\t\t# krok optymalizatora kontrolującego hiperparametry treningu\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t# statystyki tego jak model sobie radzi\n",
        "\tloss_total = 0\n",
        "\tguesses_right = 0\n",
        "\t# ustawienie modelu w tryb predykcji\n",
        "\tmodel.eval()\n",
        "\t# nie uczymy modelu, więc nie należy obliczać gradientów\n",
        "\twith torch.no_grad():\n",
        "\t\tfor images, labels in test_data_loader:\n",
        "\t\t\timages = images.to(device)\n",
        "\t\t\tlabels = labels.to(device)\n",
        "\n",
        "\t\t\toutput = model(images)\n",
        "\t\t\tloss = loss_fn(output, labels)\n",
        "\n",
        "\t\t\t# którą klasę model wybrał jako najbardziej prawdopodobną\n",
        "\t\t\tpredictions = torch.max(output, 1)[1]\n",
        "\n",
        "\t\t\tguesses_right += (predictions == labels).sum()\n",
        "\t\t\tloss_total += loss.item()\n",
        "\n",
        "\treturn loss_total, guesses_right"
      ],
      "metadata": {
        "id": "5bbbk7IMiSo_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# czy wypisać podsumowanie modelu\n",
        "print_summary = True\n",
        "print_datasets = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# ustalenie hiperparametrów treningu oraz wczytanie modelu wraz z wagami\n",
        "batch_size = 32\n",
        "max_epoch = 100\n",
        "lr = 0.001\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "weights = EfficientNet_B1_Weights.DEFAULT\n",
        "model = efficientnet_b1(weights=weights)\n",
        "# zamiana ostatnie warstwy modelu, która służyła do klasyfikacji dla 100 klas\n",
        "# na warstwe służącą do klasyfikacji dla odpowiedniej dla nas liczby klas (35)\n",
        "features_in = model.classifier[1].in_features\n",
        "model.classifier = nn.Linear(features_in, len(CHARS))\n",
        "model = model.to(device)\n",
        "preprocess = weights.transforms()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "if print_summary == True:\n",
        "\tsummary(model, torch.randn(1, 3, 256, 256).to(device))\n",
        "\n",
        "# wczytanie datasetu i podzielenie go na zbior treningowy i testowy\n",
        "dataset = CustomDataset(\"labels.txt\", \"characters\")\n",
        "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "if print_datasets == True:\n",
        "\ttrain_chars_count = [0 for _ in CHARS]\n",
        "\ttest_chars_count = [0 for _ in CHARS]\n",
        "\ttotal_chars_count = [0 for _ in CHARS]\n",
        "\tfor _, labels in train_data_loader:\n",
        "\t\tfor label in labels:\n",
        "\t\t\ttrain_chars_count[label] += 1\n",
        "\t\t\ttotal_chars_count[label] += 1\n",
        "\tfor _, labels in test_data_loader:\n",
        "\t\tfor label in labels:\n",
        "\t\t\ttest_chars_count[label] += 1\n",
        "\t\t\ttotal_chars_count[label] += 1\n",
        "\tprint(f\"char: train_count|test_count/total_count\")\n",
        "\tfor char, train_count, test_count, total_count in \\\n",
        "\t\tzip(CHARS, train_chars_count, test_chars_count, total_chars_count):\n",
        "            print(f\"{char}: {train_count}|{test_count}/{total_count}\")\n",
        "\n",
        "# statystki związane z testowaniem i treningiem\n",
        "lowest_loss = math.inf\n",
        "total_test_batches = len(test_data_loader)\n",
        "total_test_data = len(test_dataset)\n",
        "total_time = 0\n",
        "\n",
        "# pętla treningu i testowania\n",
        "for epoch in range(max_epoch):\n",
        "\tt0 = time.time()\n",
        "\tprint(f'Epoch: {epoch+1}/{max_epoch}')\n",
        "\n",
        "\ttotal_loss, right_guesses = trainAndTest(model, optimizer, train_data_loader,\n",
        "\t                        test_data_loader, loss_function, device, preprocess)\n",
        "\n",
        "\t# obliczenie statystyk dla danej epoki\n",
        "\tepoch_time = time.time() - t0\n",
        "\ttotal_time += epoch_time\n",
        "\tavg_val_loss = total_loss/total_test_batches\n",
        "\tprint('avg_val_loss: {:.4f}, val_acc: {:.4f}\\nEpoch Time = {:.2f}, Cumulative Time = {:.2f}\\n'.format(avg_val_loss, right_guesses/total_test_data, epoch_time, total_time))\n",
        "\n",
        "\t# zapisanie najlepszych dotychczas wag\n",
        "\tif avg_val_loss < lowest_loss:\n",
        "\t\tlowest_loss = avg_val_loss\n",
        "\t\ttorch.save({\n",
        "\t\t\t'lowest_loss': lowest_loss,\n",
        "\t\t\t'model_state_dict': model.state_dict(),\n",
        "\t\t\t'optimizer_state_dict': optimizer.state_dict(),\n",
        "\t\t}, f'best_weights.pt')\n",
        "\n",
        "# zapisanie ostatnich uzyskanych wag\n",
        "torch.save({\n",
        "\t'lowest_loss': lowest_loss,\n",
        "\t'model_state_dict': model.state_dict(),\n",
        "\t'optimizer_state_dict': optimizer.state_dict(),\n",
        "\t}, f'last_weights.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW7NIosYs7Ic",
        "outputId": "9d5bb44d-7cf5-4585-e93b-21ba3f88abd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "├─Sequential: 1-1                             [-1, 1280, 8, 8]          --\n",
            "|    └─Conv2dNormActivation: 2-1              [-1, 32, 128, 128]        --\n",
            "|    |    └─Conv2d: 3-1                       [-1, 32, 128, 128]        864\n",
            "|    |    └─BatchNorm2d: 3-2                  [-1, 32, 128, 128]        64\n",
            "|    |    └─SiLU: 3-3                         [-1, 32, 128, 128]        --\n",
            "|    └─Sequential: 2-2                        [-1, 16, 128, 128]        --\n",
            "|    |    └─MBConv: 3-4                       [-1, 16, 128, 128]        1,448\n",
            "|    |    └─MBConv: 3-5                       [-1, 16, 128, 128]        612\n",
            "|    └─Sequential: 2-3                        [-1, 24, 64, 64]          --\n",
            "|    |    └─MBConv: 3-6                       [-1, 24, 64, 64]          6,004\n",
            "|    |    └─MBConv: 3-7                       [-1, 24, 64, 64]          10,710\n",
            "|    |    └─MBConv: 3-8                       [-1, 24, 64, 64]          10,710\n",
            "|    └─Sequential: 2-4                        [-1, 40, 32, 32]          --\n",
            "|    |    └─MBConv: 3-9                       [-1, 40, 32, 32]          15,350\n",
            "|    |    └─MBConv: 3-10                      [-1, 40, 32, 32]          31,290\n",
            "|    |    └─MBConv: 3-11                      [-1, 40, 32, 32]          31,290\n",
            "|    └─Sequential: 2-5                        [-1, 80, 16, 16]          --\n",
            "|    |    └─MBConv: 3-12                      [-1, 80, 16, 16]          37,130\n",
            "|    |    └─MBConv: 3-13                      [-1, 80, 16, 16]          102,900\n",
            "|    |    └─MBConv: 3-14                      [-1, 80, 16, 16]          102,900\n",
            "|    |    └─MBConv: 3-15                      [-1, 80, 16, 16]          102,900\n",
            "|    └─Sequential: 2-6                        [-1, 112, 16, 16]         --\n",
            "|    |    └─MBConv: 3-16                      [-1, 112, 16, 16]         126,004\n",
            "|    |    └─MBConv: 3-17                      [-1, 112, 16, 16]         208,572\n",
            "|    |    └─MBConv: 3-18                      [-1, 112, 16, 16]         208,572\n",
            "|    |    └─MBConv: 3-19                      [-1, 112, 16, 16]         208,572\n",
            "|    └─Sequential: 2-7                        [-1, 192, 8, 8]           --\n",
            "|    |    └─MBConv: 3-20                      [-1, 192, 8, 8]           262,492\n",
            "|    |    └─MBConv: 3-21                      [-1, 192, 8, 8]           587,952\n",
            "|    |    └─MBConv: 3-22                      [-1, 192, 8, 8]           587,952\n",
            "|    |    └─MBConv: 3-23                      [-1, 192, 8, 8]           587,952\n",
            "|    |    └─MBConv: 3-24                      [-1, 192, 8, 8]           587,952\n",
            "|    └─Sequential: 2-8                        [-1, 320, 8, 8]           --\n",
            "|    |    └─MBConv: 3-25                      [-1, 320, 8, 8]           717,232\n",
            "|    |    └─MBConv: 3-26                      [-1, 320, 8, 8]           1,563,600\n",
            "|    └─Conv2dNormActivation: 2-9              [-1, 1280, 8, 8]          --\n",
            "|    |    └─Conv2d: 3-27                      [-1, 1280, 8, 8]          409,600\n",
            "|    |    └─BatchNorm2d: 3-28                 [-1, 1280, 8, 8]          2,560\n",
            "|    |    └─SiLU: 3-29                        [-1, 1280, 8, 8]          --\n",
            "├─AdaptiveAvgPool2d: 1-2                      [-1, 1280, 1, 1]          --\n",
            "├─Linear: 1-3                                 [-1, 35]                  44,835\n",
            "===============================================================================================\n",
            "Total params: 6,558,019\n",
            "Trainable params: 6,558,019\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 65.46\n",
            "===============================================================================================\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 9.25\n",
            "Params size (MB): 25.02\n",
            "Estimated Total Size (MB): 35.02\n",
            "===============================================================================================\n",
            "char: train_count|test_count/total_count\n",
            "0: 52|13/65\n",
            "1: 60|18/78\n",
            "2: 61|16/77\n",
            "3: 47|7/54\n",
            "4: 50|14/64\n",
            "5: 52|9/61\n",
            "6: 49|13/62\n",
            "7: 61|17/78\n",
            "8: 60|12/72\n",
            "9: 60|15/75\n",
            "A: 23|6/29\n",
            "B: 15|4/19\n",
            "C: 21|7/28\n",
            "D: 1|1/2\n",
            "E: 10|10/20\n",
            "F: 13|3/16\n",
            "G: 14|4/18\n",
            "H: 9|2/11\n",
            "I: 11|4/15\n",
            "J: 20|3/23\n",
            "K: 36|11/47\n",
            "L: 30|3/33\n",
            "M: 18|4/22\n",
            "N: 8|1/9\n",
            "O: 11|4/15\n",
            "P: 8|4/12\n",
            "R: 11|2/13\n",
            "S: 144|30/174\n",
            "T: 27|8/35\n",
            "U: 6|3/9\n",
            "V: 11|3/14\n",
            "W: 16|0/16\n",
            "X: 7|1/8\n",
            "Y: 5|2/7\n",
            "Z: 11|5/16\n",
            "Epoch: 1/100\n",
            "avg_val_loss: 0.7713, val_acc: 0.7568\n",
            "Epoch Time = 9.14, Cumulative Time = 9.14\n",
            "\n",
            "Epoch: 2/100\n",
            "avg_val_loss: 0.2129, val_acc: 0.9382\n",
            "Epoch Time = 8.46, Cumulative Time = 17.60\n",
            "\n",
            "Epoch: 3/100\n",
            "avg_val_loss: 0.2875, val_acc: 0.9228\n",
            "Epoch Time = 8.50, Cumulative Time = 26.10\n",
            "\n",
            "Epoch: 4/100\n",
            "avg_val_loss: 0.2747, val_acc: 0.8842\n",
            "Epoch Time = 8.54, Cumulative Time = 34.64\n",
            "\n",
            "Epoch: 5/100\n",
            "avg_val_loss: 0.1360, val_acc: 0.9575\n",
            "Epoch Time = 8.59, Cumulative Time = 43.23\n",
            "\n",
            "Epoch: 6/100\n",
            "avg_val_loss: 0.1554, val_acc: 0.9459\n",
            "Epoch Time = 8.66, Cumulative Time = 51.89\n",
            "\n",
            "Epoch: 7/100\n",
            "avg_val_loss: 0.1362, val_acc: 0.9575\n",
            "Epoch Time = 9.12, Cumulative Time = 61.01\n",
            "\n",
            "Epoch: 8/100\n",
            "avg_val_loss: 0.0725, val_acc: 0.9730\n",
            "Epoch Time = 9.07, Cumulative Time = 70.08\n",
            "\n",
            "Epoch: 9/100\n",
            "avg_val_loss: 0.2155, val_acc: 0.9035\n",
            "Epoch Time = 8.91, Cumulative Time = 78.99\n",
            "\n",
            "Epoch: 10/100\n",
            "avg_val_loss: 0.4929, val_acc: 0.8764\n",
            "Epoch Time = 9.10, Cumulative Time = 88.10\n",
            "\n",
            "Epoch: 11/100\n",
            "avg_val_loss: 0.7892, val_acc: 0.8533\n",
            "Epoch Time = 8.75, Cumulative Time = 96.85\n",
            "\n",
            "Epoch: 12/100\n",
            "avg_val_loss: 0.1848, val_acc: 0.9151\n",
            "Epoch Time = 8.71, Cumulative Time = 105.55\n",
            "\n",
            "Epoch: 13/100\n",
            "avg_val_loss: 0.1569, val_acc: 0.9730\n",
            "Epoch Time = 8.69, Cumulative Time = 114.24\n",
            "\n",
            "Epoch: 14/100\n",
            "avg_val_loss: 0.3206, val_acc: 0.9151\n",
            "Epoch Time = 8.69, Cumulative Time = 122.94\n",
            "\n",
            "Epoch: 15/100\n",
            "avg_val_loss: 0.2097, val_acc: 0.9459\n",
            "Epoch Time = 8.70, Cumulative Time = 131.63\n",
            "\n",
            "Epoch: 16/100\n",
            "avg_val_loss: 0.1001, val_acc: 0.9691\n",
            "Epoch Time = 8.71, Cumulative Time = 140.35\n",
            "\n",
            "Epoch: 17/100\n",
            "avg_val_loss: 0.1224, val_acc: 0.9614\n",
            "Epoch Time = 8.70, Cumulative Time = 149.05\n",
            "\n",
            "Epoch: 18/100\n",
            "avg_val_loss: 0.0263, val_acc: 0.9846\n",
            "Epoch Time = 8.76, Cumulative Time = 157.81\n",
            "\n",
            "Epoch: 19/100\n",
            "avg_val_loss: 0.0268, val_acc: 0.9884\n",
            "Epoch Time = 8.76, Cumulative Time = 166.57\n",
            "\n",
            "Epoch: 20/100\n",
            "avg_val_loss: 0.0983, val_acc: 0.9691\n",
            "Epoch Time = 8.71, Cumulative Time = 175.28\n",
            "\n",
            "Epoch: 21/100\n",
            "avg_val_loss: 0.0960, val_acc: 0.9653\n",
            "Epoch Time = 8.76, Cumulative Time = 184.05\n",
            "\n",
            "Epoch: 22/100\n",
            "avg_val_loss: 0.1103, val_acc: 0.9653\n",
            "Epoch Time = 8.74, Cumulative Time = 192.78\n",
            "\n",
            "Epoch: 23/100\n",
            "avg_val_loss: 0.0584, val_acc: 0.9846\n",
            "Epoch Time = 8.70, Cumulative Time = 201.48\n",
            "\n",
            "Epoch: 24/100\n",
            "avg_val_loss: 0.0420, val_acc: 0.9923\n",
            "Epoch Time = 8.71, Cumulative Time = 210.19\n",
            "\n",
            "Epoch: 25/100\n",
            "avg_val_loss: 0.0886, val_acc: 0.9768\n",
            "Epoch Time = 8.69, Cumulative Time = 218.88\n",
            "\n",
            "Epoch: 26/100\n",
            "avg_val_loss: 0.2071, val_acc: 0.9189\n",
            "Epoch Time = 8.71, Cumulative Time = 227.60\n",
            "\n",
            "Epoch: 27/100\n",
            "avg_val_loss: 0.1901, val_acc: 0.9382\n",
            "Epoch Time = 8.69, Cumulative Time = 236.29\n",
            "\n",
            "Epoch: 28/100\n",
            "avg_val_loss: 0.2062, val_acc: 0.9421\n",
            "Epoch Time = 8.70, Cumulative Time = 244.99\n",
            "\n",
            "Epoch: 29/100\n",
            "avg_val_loss: 0.3330, val_acc: 0.9035\n",
            "Epoch Time = 8.75, Cumulative Time = 253.73\n",
            "\n",
            "Epoch: 30/100\n",
            "avg_val_loss: 0.1427, val_acc: 0.9614\n",
            "Epoch Time = 8.71, Cumulative Time = 262.45\n",
            "\n",
            "Epoch: 31/100\n",
            "avg_val_loss: 0.1440, val_acc: 0.9421\n",
            "Epoch Time = 8.75, Cumulative Time = 271.20\n",
            "\n",
            "Epoch: 32/100\n",
            "avg_val_loss: 0.0396, val_acc: 0.9846\n",
            "Epoch Time = 8.74, Cumulative Time = 279.94\n",
            "\n",
            "Epoch: 33/100\n",
            "avg_val_loss: 0.0305, val_acc: 0.9923\n",
            "Epoch Time = 8.71, Cumulative Time = 288.65\n",
            "\n",
            "Epoch: 34/100\n",
            "avg_val_loss: 0.0432, val_acc: 0.9846\n",
            "Epoch Time = 8.75, Cumulative Time = 297.39\n",
            "\n",
            "Epoch: 35/100\n",
            "avg_val_loss: 0.0848, val_acc: 0.9653\n",
            "Epoch Time = 8.75, Cumulative Time = 306.15\n",
            "\n",
            "Epoch: 36/100\n",
            "avg_val_loss: 0.0773, val_acc: 0.9653\n",
            "Epoch Time = 8.72, Cumulative Time = 314.87\n",
            "\n",
            "Epoch: 37/100\n",
            "avg_val_loss: 0.3418, val_acc: 0.8880\n",
            "Epoch Time = 8.77, Cumulative Time = 323.64\n",
            "\n",
            "Epoch: 38/100\n",
            "avg_val_loss: 0.3578, val_acc: 0.8996\n",
            "Epoch Time = 8.72, Cumulative Time = 332.36\n",
            "\n",
            "Epoch: 39/100\n",
            "avg_val_loss: 0.6886, val_acc: 0.8069\n",
            "Epoch Time = 8.70, Cumulative Time = 341.06\n",
            "\n",
            "Epoch: 40/100\n",
            "avg_val_loss: 1.0198, val_acc: 0.7375\n",
            "Epoch Time = 8.74, Cumulative Time = 349.80\n",
            "\n",
            "Epoch: 41/100\n",
            "avg_val_loss: 0.2688, val_acc: 0.9498\n",
            "Epoch Time = 8.71, Cumulative Time = 358.51\n",
            "\n",
            "Epoch: 42/100\n",
            "avg_val_loss: 0.0410, val_acc: 0.9846\n",
            "Epoch Time = 8.71, Cumulative Time = 367.22\n",
            "\n",
            "Epoch: 43/100\n",
            "avg_val_loss: 0.4228, val_acc: 0.8880\n",
            "Epoch Time = 8.70, Cumulative Time = 375.92\n",
            "\n",
            "Epoch: 44/100\n",
            "avg_val_loss: 0.4705, val_acc: 0.8919\n",
            "Epoch Time = 8.71, Cumulative Time = 384.63\n",
            "\n",
            "Epoch: 45/100\n",
            "avg_val_loss: 0.2727, val_acc: 0.9112\n",
            "Epoch Time = 8.71, Cumulative Time = 393.34\n",
            "\n",
            "Epoch: 46/100\n",
            "avg_val_loss: 0.1280, val_acc: 0.9382\n",
            "Epoch Time = 8.80, Cumulative Time = 402.14\n",
            "\n",
            "Epoch: 47/100\n",
            "avg_val_loss: 0.1897, val_acc: 0.9498\n",
            "Epoch Time = 8.73, Cumulative Time = 410.88\n",
            "\n",
            "Epoch: 48/100\n",
            "avg_val_loss: 0.1432, val_acc: 0.9382\n",
            "Epoch Time = 8.72, Cumulative Time = 419.59\n",
            "\n",
            "Epoch: 49/100\n",
            "avg_val_loss: 0.1227, val_acc: 0.9421\n",
            "Epoch Time = 8.70, Cumulative Time = 428.29\n",
            "\n",
            "Epoch: 50/100\n",
            "avg_val_loss: 0.1245, val_acc: 0.9537\n",
            "Epoch Time = 8.73, Cumulative Time = 437.02\n",
            "\n",
            "Epoch: 51/100\n",
            "avg_val_loss: 0.1380, val_acc: 0.9421\n",
            "Epoch Time = 8.73, Cumulative Time = 445.75\n",
            "\n",
            "Epoch: 52/100\n",
            "avg_val_loss: 0.1278, val_acc: 0.9498\n",
            "Epoch Time = 8.70, Cumulative Time = 454.46\n",
            "\n",
            "Epoch: 53/100\n",
            "avg_val_loss: 0.1346, val_acc: 0.9498\n",
            "Epoch Time = 8.76, Cumulative Time = 463.21\n",
            "\n",
            "Epoch: 54/100\n",
            "avg_val_loss: 0.0332, val_acc: 0.9768\n",
            "Epoch Time = 8.73, Cumulative Time = 471.95\n",
            "\n",
            "Epoch: 55/100\n",
            "avg_val_loss: 0.2275, val_acc: 0.9266\n",
            "Epoch Time = 8.70, Cumulative Time = 480.65\n",
            "\n",
            "Epoch: 56/100\n",
            "avg_val_loss: 0.1698, val_acc: 0.9344\n",
            "Epoch Time = 8.73, Cumulative Time = 489.38\n",
            "\n",
            "Epoch: 57/100\n",
            "avg_val_loss: 0.1381, val_acc: 0.9305\n",
            "Epoch Time = 8.71, Cumulative Time = 498.09\n",
            "\n",
            "Epoch: 58/100\n",
            "avg_val_loss: 0.1579, val_acc: 0.9266\n",
            "Epoch Time = 8.72, Cumulative Time = 506.81\n",
            "\n",
            "Epoch: 59/100\n",
            "avg_val_loss: 0.2598, val_acc: 0.9421\n",
            "Epoch Time = 8.71, Cumulative Time = 515.52\n",
            "\n",
            "Epoch: 60/100\n",
            "avg_val_loss: 0.1270, val_acc: 0.9421\n",
            "Epoch Time = 8.71, Cumulative Time = 524.22\n",
            "\n",
            "Epoch: 61/100\n",
            "avg_val_loss: 0.1714, val_acc: 0.9459\n",
            "Epoch Time = 8.69, Cumulative Time = 532.92\n",
            "\n",
            "Epoch: 62/100\n",
            "avg_val_loss: 0.1339, val_acc: 0.9498\n",
            "Epoch Time = 8.70, Cumulative Time = 541.62\n",
            "\n",
            "Epoch: 63/100\n",
            "avg_val_loss: 0.1139, val_acc: 0.9575\n",
            "Epoch Time = 8.73, Cumulative Time = 550.35\n",
            "\n",
            "Epoch: 64/100\n",
            "avg_val_loss: 0.1333, val_acc: 0.9537\n",
            "Epoch Time = 8.71, Cumulative Time = 559.07\n",
            "\n",
            "Epoch: 65/100\n",
            "avg_val_loss: 0.1078, val_acc: 0.9614\n",
            "Epoch Time = 8.72, Cumulative Time = 567.78\n",
            "\n",
            "Epoch: 66/100\n",
            "avg_val_loss: 0.1119, val_acc: 0.9575\n",
            "Epoch Time = 8.74, Cumulative Time = 576.52\n",
            "\n",
            "Epoch: 67/100\n",
            "avg_val_loss: 0.2347, val_acc: 0.9498\n",
            "Epoch Time = 8.74, Cumulative Time = 585.26\n",
            "\n",
            "Epoch: 68/100\n",
            "avg_val_loss: 0.1033, val_acc: 0.9614\n",
            "Epoch Time = 8.71, Cumulative Time = 593.96\n",
            "\n",
            "Epoch: 69/100\n",
            "avg_val_loss: 0.0945, val_acc: 0.9691\n",
            "Epoch Time = 8.75, Cumulative Time = 602.72\n",
            "\n",
            "Epoch: 70/100\n",
            "avg_val_loss: 0.0817, val_acc: 0.9768\n",
            "Epoch Time = 8.73, Cumulative Time = 611.45\n",
            "\n",
            "Epoch: 71/100\n",
            "avg_val_loss: 0.1055, val_acc: 0.9691\n",
            "Epoch Time = 8.71, Cumulative Time = 620.16\n",
            "\n",
            "Epoch: 72/100\n",
            "avg_val_loss: 1.1811, val_acc: 0.7143\n",
            "Epoch Time = 8.75, Cumulative Time = 628.91\n",
            "\n",
            "Epoch: 73/100\n",
            "avg_val_loss: 0.6601, val_acc: 0.8224\n",
            "Epoch Time = 8.71, Cumulative Time = 637.62\n",
            "\n",
            "Epoch: 74/100\n",
            "avg_val_loss: 0.0832, val_acc: 0.9653\n",
            "Epoch Time = 8.71, Cumulative Time = 646.33\n",
            "\n",
            "Epoch: 75/100\n",
            "avg_val_loss: 0.0667, val_acc: 0.9730\n",
            "Epoch Time = 8.70, Cumulative Time = 655.03\n",
            "\n",
            "Epoch: 76/100\n",
            "avg_val_loss: 0.0400, val_acc: 0.9884\n",
            "Epoch Time = 8.71, Cumulative Time = 663.74\n",
            "\n",
            "Epoch: 77/100\n",
            "avg_val_loss: 0.0609, val_acc: 0.9730\n",
            "Epoch Time = 8.70, Cumulative Time = 672.43\n",
            "\n",
            "Epoch: 78/100\n",
            "avg_val_loss: 0.0785, val_acc: 0.9730\n",
            "Epoch Time = 8.72, Cumulative Time = 681.15\n",
            "\n",
            "Epoch: 79/100\n",
            "avg_val_loss: 0.2081, val_acc: 0.9498\n",
            "Epoch Time = 8.74, Cumulative Time = 689.90\n",
            "\n",
            "Epoch: 80/100\n",
            "avg_val_loss: 0.1128, val_acc: 0.9575\n",
            "Epoch Time = 8.73, Cumulative Time = 698.63\n",
            "\n",
            "Epoch: 81/100\n",
            "avg_val_loss: 0.1481, val_acc: 0.9614\n",
            "Epoch Time = 8.73, Cumulative Time = 707.35\n",
            "\n",
            "Epoch: 82/100\n",
            "avg_val_loss: 0.0535, val_acc: 0.9691\n",
            "Epoch Time = 8.74, Cumulative Time = 716.10\n",
            "\n",
            "Epoch: 83/100\n",
            "avg_val_loss: 0.0766, val_acc: 0.9768\n",
            "Epoch Time = 8.73, Cumulative Time = 724.83\n",
            "\n",
            "Epoch: 84/100\n",
            "avg_val_loss: 0.1792, val_acc: 0.9537\n",
            "Epoch Time = 8.70, Cumulative Time = 733.53\n",
            "\n",
            "Epoch: 85/100\n",
            "avg_val_loss: 0.0558, val_acc: 0.9768\n",
            "Epoch Time = 8.76, Cumulative Time = 742.29\n",
            "\n",
            "Epoch: 86/100\n",
            "avg_val_loss: 0.2317, val_acc: 0.9112\n",
            "Epoch Time = 8.73, Cumulative Time = 751.03\n",
            "\n",
            "Epoch: 87/100\n",
            "avg_val_loss: 0.1380, val_acc: 0.9459\n",
            "Epoch Time = 8.70, Cumulative Time = 759.73\n",
            "\n",
            "Epoch: 88/100\n",
            "avg_val_loss: 0.1667, val_acc: 0.9459\n",
            "Epoch Time = 8.71, Cumulative Time = 768.44\n",
            "\n",
            "Epoch: 89/100\n",
            "avg_val_loss: 0.1655, val_acc: 0.9421\n",
            "Epoch Time = 8.69, Cumulative Time = 777.12\n",
            "\n",
            "Epoch: 90/100\n",
            "avg_val_loss: 0.4629, val_acc: 0.9344\n",
            "Epoch Time = 8.70, Cumulative Time = 785.82\n",
            "\n",
            "Epoch: 91/100\n",
            "avg_val_loss: 0.2618, val_acc: 0.9344\n",
            "Epoch Time = 8.71, Cumulative Time = 794.53\n",
            "\n",
            "Epoch: 92/100\n",
            "avg_val_loss: 0.3502, val_acc: 0.9459\n",
            "Epoch Time = 8.73, Cumulative Time = 803.26\n",
            "\n",
            "Epoch: 93/100\n",
            "avg_val_loss: 0.1722, val_acc: 0.9575\n",
            "Epoch Time = 8.72, Cumulative Time = 811.98\n",
            "\n",
            "Epoch: 94/100\n",
            "avg_val_loss: 0.1709, val_acc: 0.9498\n",
            "Epoch Time = 8.70, Cumulative Time = 820.68\n",
            "\n",
            "Epoch: 95/100\n",
            "avg_val_loss: 0.2053, val_acc: 0.9459\n",
            "Epoch Time = 8.74, Cumulative Time = 829.42\n",
            "\n",
            "Epoch: 96/100\n",
            "avg_val_loss: 0.1840, val_acc: 0.9498\n",
            "Epoch Time = 8.72, Cumulative Time = 838.14\n",
            "\n",
            "Epoch: 97/100\n",
            "avg_val_loss: 0.2142, val_acc: 0.9498\n",
            "Epoch Time = 8.71, Cumulative Time = 846.85\n",
            "\n",
            "Epoch: 98/100\n",
            "avg_val_loss: 0.1765, val_acc: 0.9537\n",
            "Epoch Time = 8.73, Cumulative Time = 855.57\n",
            "\n",
            "Epoch: 99/100\n",
            "avg_val_loss: 0.1006, val_acc: 0.9614\n",
            "Epoch Time = 8.69, Cumulative Time = 864.26\n",
            "\n",
            "Epoch: 100/100\n",
            "avg_val_loss: 0.1098, val_acc: 0.9614\n",
            "Epoch Time = 8.70, Cumulative Time = 872.96\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zapisanie datasetu i modelu na dysku"
      ],
      "metadata": {
        "id": "ym361oByOz-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!scp drive/MyDrive/Sem5/AO/best_weights.pt ./"
      ],
      "metadata": {
        "id": "mkkniLXKPvB-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"best_weights.pt\", map_location=torch.device('cpu'), weights_only=True)\n",
        "torch.save({\n",
        "\t'model_state_dict': checkpoint[\"model_state_dict\"],\n",
        "\t}, f'best_weights_only.pt')"
      ],
      "metadata": {
        "id": "lD92xlkdPa94"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3-EnFJawaT9",
        "outputId": "09dabf83-ec7f-4406-b037-aef0e913728a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!scp -r characters drive/MyDrive/Sem5/AO\n",
        "!scp labels.txt drive/MyDrive/Sem5/AO\n",
        "!scp best_weights_only.pt drive/MyDrive/Sem5/AO"
      ],
      "metadata": {
        "id": "7fk9kA8KwdvP"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}